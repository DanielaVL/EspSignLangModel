{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-04 21:16:52.199831: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-06-04 21:16:52.250782: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-04 21:16:53.568842: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import time\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from tensorflow import keras\n",
    "\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "os.environ['GLOG_minloglevel'] = '2' \n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para dibujar los puntos de referencia de la mano y las conexiones entre ellos\n",
    "def draw_hand_landmarks(frame, landmarks, COLOR, margin=30):\n",
    "    height, width, _ = frame.shape  # Obtiene las dimensiones del frame\n",
    "    x_min, y_min, x_max, y_max = width, height, 0, 0  # Inicializa los límites del rectángulo que rodea la mano\n",
    "\n",
    "    for i, point in enumerate(landmarks.landmark):\n",
    "        x, y = int(point.x * width), int(point.y * height)  # Calcula las coordenadas del punto en píxeles\n",
    "        color = (0, 255, 0) if i % 4 == 0 else (0, 0, 255)  # Alterna el color entre verde y rojo para cada punto\n",
    "        cv2.circle(frame, (x, y), int(height * 0.01), color, -1)  # Dibuja un círculo en el punto\n",
    "\n",
    "        # Actualiza las coordenadas mínimas y máximas para dibujar un rectángulo alrededor de la mano\n",
    "        x_min = min(x_min, x)\n",
    "        y_min = min(y_min, y)\n",
    "        x_max = max(x_max, x)\n",
    "        y_max = max(y_max, y)\n",
    "\n",
    "    # Definir conexiones solo para el contorno de la mano y los dedos\n",
    "    connections = [[1, 2], [2, 3], [3, 4],  # Dedo pulgar\n",
    "                   [5, 6], [6, 7], [7, 8],  # Dedo índice\n",
    "                   [9, 10], [10, 11], [11, 12],  # Dedo medio\n",
    "                   [13, 14], [14, 15], [15, 16],  # Dedo anular\n",
    "                   [17, 18], [18, 19], [19, 20],  # Dedo meñique\n",
    "                   [0, 1],[0, 17],[1, 5], [5, 9], [9, 13], [13, 17]]  # Conexiones de la palma de la mano\n",
    "\n",
    "    # Dibujar las conexiones entre los puntos de referencia de la mano\n",
    "    for connection in connections:\n",
    "        cv2.line(frame, (int(landmarks.landmark[connection[0]].x * width), int(landmarks.landmark[connection[0]].y * height)),\n",
    "                         (int(landmarks.landmark[connection[1]].x * width), int(landmarks.landmark[connection[1]].y * height)), COLOR, 2)\n",
    "\n",
    "    hand_width = x_max - x_min\n",
    "    hand_height = y_max - y_min\n",
    "\n",
    "    # Calculate the side length of the square bounding box\n",
    "    square_side = max(hand_width, hand_height)\n",
    "\n",
    "    # Calculate the coordinates of the square bounding box\n",
    "    x_min_square = x_min + hand_width // 2 - square_side // 2\n",
    "    x_max_square = x_min_square + square_side\n",
    "    y_min_square = y_min + hand_height // 2 - square_side // 2\n",
    "    y_max_square = y_min_square + square_side\n",
    "\n",
    "    # Añadir un margen al cuadrado\n",
    "    x_min_square = max(0, x_min_square)\n",
    "    y_min_square = max(0, y_min_square)\n",
    "    x_max_square = min(width, x_max_square)\n",
    "    y_max_square = min(height, y_max_square)\n",
    "\n",
    "    # Dibujar el cuadrado que rodea la mano\n",
    "    cv2.rectangle(frame, (x_min_square-margin, y_min_square-margin), (x_max_square+margin, y_max_square+margin), COLOR, 2)\n",
    "\n",
    "    # Return the square bounding box instead of the hand rectangle\n",
    "    return frame, (x_min_square-margin, y_min_square-margin, x_max_square+margin, y_max_square+margin)\n",
    "\n",
    "# Función para mapear las etiquetas\n",
    "def getLetter(result):\n",
    "    classlabels = {'A': 0,\n",
    "                    'B': 1,\n",
    "                    'C': 2,\n",
    "                    'D': 3,\n",
    "                    'E': 4,\n",
    "                    'F': 5,\n",
    "                    'G': 6,\n",
    "                    'I': 7,\n",
    "                    'K': 8,\n",
    "                    'L': 9,\n",
    "                    'M': 10,\n",
    "                    'N': 11,\n",
    "                    'O': 12,\n",
    "                    'P': 13,\n",
    "                    'Q': 14,\n",
    "                    'R': 15,\n",
    "                    'S': 16,\n",
    "                    'T': 17,\n",
    "                    'U': 18}\n",
    "    \n",
    "    try:\n",
    "        return classlabels[int(result)]\n",
    "    except Exception as e:\n",
    "        # retornar la letra correspondiente al resultado\n",
    "        return list(classlabels.keys())[list(classlabels.values()).index(result)]\n",
    "\n",
    "# Función para capturar frames de la cámara y guardarlos en carpetas correspondientes a cada letra\n",
    "def capture_frames(hands, model, path):\n",
    "\n",
    "    cap = cv2.VideoCapture(0)  # Inicializa la cámara\n",
    "    start_time = time.time()  # Inicializa el tiempo de captura\n",
    "    frame_count = 0  # Inicializa el contador de frames\n",
    "\n",
    "    texto = ''\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()  # Lee un frame de la cámara\n",
    "        letter = ''\n",
    "\n",
    "        # Si no se pudo leer el frame, termina el ciclo\n",
    "        if not ret:\n",
    "            print(\"Error al leer el frame\")\n",
    "            break\n",
    "\n",
    "        img = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)  # Convierte el frame de BGR a RGB\n",
    "\n",
    "        hands_results = hands.process(img)  # Procesa el frame con el modelo de manos\n",
    "\n",
    "        drawn_frame = frame.copy()  # Crea una copia del frame\n",
    "\n",
    "        # Dibuja puntos y líneas para las manos en la imagen negra\n",
    "        if hands_results.multi_hand_landmarks:\n",
    "            for landmarks in hands_results.multi_hand_landmarks:\n",
    "                drawn_frame, hand_rect = draw_hand_landmarks(frame, landmarks, (0, 0, 255))  # Dibuja puntos y líneas para las manos\n",
    "\n",
    "                # recortar la mano y guardarla \n",
    "                try:\n",
    "                    reshaped_frame = drawn_frame[hand_rect[1]:hand_rect[3], hand_rect[0]:hand_rect[2]] # Recorta el cuadrado que rodea la mano y lo redimensiona\n",
    "                    #reshaped_frame = cv2.flip(reshaped_frame, 1)  # Voltea la imagen horizontalmente\n",
    "                    reshaped_frame = cv2.cvtColor(reshaped_frame, cv2.COLOR_BGR2GRAY)  # Convierte la imagen a escala de grises\n",
    "                    reshaped_frame = cv2.resize(reshaped_frame, (28, 28), interpolation=cv2.INTER_AREA) # Redimensiona la imagen a 28x28 píxel  es\n",
    "\n",
    "                    reshaped_frame = reshaped_frame.reshape(1, 28, 28,  1)\n",
    "\n",
    "                    result = np.argmax(model.predict(reshaped_frame, verbose=0), axis=-1)[0]  # Clasifica la imagen\n",
    "                    letter = getLetter(result)\n",
    "                    \n",
    "                    if letter == 'Q':\n",
    "                        cv2.putText(frame, f'Borrar', (10, 40), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), 2)\n",
    "                        if (frame_count % 60 == 0):\n",
    "                            texto = texto[:-1]\n",
    "\n",
    "                    elif letter == 'O':\n",
    "                        cv2.putText(frame, f'Espacio', (10, 40), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), 2)\n",
    "                        if (frame_count % 60 == 0):\n",
    "                            texto += ' '\n",
    "\n",
    "                    elif letter == 'B':\n",
    "                        cv2.putText(frame, f'Guardar', (10, 40), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), 2)\n",
    "                        if (texto != '') and (frame_count % 60 == 0):\n",
    "                            with open(f'{path}texto.txt', 'a') as f:\n",
    "                                f.write(texto + '\\n')\n",
    "                    else:\n",
    "                        cv2.putText(frame, f'{letter}', (10, 40), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), 2)\n",
    "                        if frame_count % 60 == 0:\n",
    "                            texto += letter\n",
    "                    frame_count += 1  # Incrementa el contador de frames\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    cv2.putText(frame, f'Error: {e}', (10, 40), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), 2)\n",
    "                    pass\n",
    "\n",
    "        elapsed_time = int(time.time() - start_time)  # Calcula el tiempo transcurrido\n",
    "        cv2.putText(frame, f'Tiempo: {elapsed_time} seg', (10, 80), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), 2)\n",
    "\n",
    "        cv2.putText(frame, f'Texto: {texto}', (10, 120), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), 2)\n",
    "        cv2.imshow('Pose Detection', frame)  # Muestra el frame con las manos detectadas\n",
    "        # Si se presiona la tecla 'q', termina el ciclo\n",
    "        if (cv2.waitKey(1) & 0xFF == ord('q')): # or letter == 'B':\n",
    "            break\n",
    "\n",
    "    cap.release()  # Libera la cámara\n",
    "    cv2.destroyAllWindows() # Cerrar todas las ventanas\n",
    "    hands.close() # Cerrar el modelo de manos\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "I0000 00:00:1717556286.365088   16138 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1717556286.365694   54230 gl_context.cc:357] GL version: 3.2 (OpenGL ES 3.2 Mesa 24.0.8-manjaro1.1), renderer: Mesa Intel(R) Xe Graphics (TGL GT2)\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.load_model('./models/model3.h5')\n",
    "path = 'out/' # \n",
    "mp_hands = mp.solutions.hands # Importar el modelo de manos de MediaPipe\n",
    "hands = mp_hands.Hands(max_num_hands=1) # Inicializar el modelo de manos\n",
    "\n",
    "capture_frames(hands, model, path) # Capturar frames cada 15 frames y guardar 100 frames por letra en la carpeta \"classes_poses_cut\"\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
