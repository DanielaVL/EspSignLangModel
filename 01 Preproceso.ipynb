{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-31 07:37:52.108968: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-05-31 07:37:52.145463: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-31 07:37:52.917288: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import time\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makedir(directory): # Función para cargar los datos\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "    return directory\n",
    "\n",
    "\n",
    "def save_plot(path, save_path=None, extra_img_path=None): # Función para guardar una imagen con cada clase\n",
    "    classes = sorted(os.listdir(path))\n",
    "    fig, axs = plt.subplots(5, 4, figsize=(20, 20))\n",
    "    plt.rcParams.update({'font.size': 22})\n",
    "    for i, c in enumerate(classes):\n",
    "        img = mpimg.imread(path + c + '/' + os.listdir(path + c)[0])\n",
    "        axs[i//4, i%4].imshow(img)\n",
    "        axs[i//4, i%4].set_title(c)\n",
    "        axs[i//4, i%4].axis('off')\n",
    "    axs[4, 3].imshow(mpimg.imread(extra_img_path))\n",
    "    axs[4, 3].axis('off')\n",
    "    plt.tight_layout()\n",
    "    if save_path:\n",
    "        plt.savefig(save_path)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_hand_landmarks(frame, landmarks, margin=15): # Función para dibujar los puntos de referencia de la mano\n",
    "    height, width, _ = frame.shape  # Obtiene las dimensiones del frame\n",
    "    x_min, y_min, x_max, y_max = width, height, 0, 0  # Inicializa los límites del rectángulo que rodea la mano\n",
    "\n",
    "    for i, point in enumerate(landmarks.landmark):\n",
    "        x, y = int(point.x * width), int(point.y * height)  # Calcula las coordenadas del punto en píxeles\n",
    "        color = (0, 255, 0) if i % 4 == 0 else (0, 0, 255)  # Alterna el color entre verde y rojo para cada punto\n",
    "        cv2.circle(frame, (x, y), int(height * 0.01), color, -1)  # Dibuja un círculo en el punto\n",
    "\n",
    "        # Actualiza las coordenadas mínimas y máximas para dibujar un rectángulo alrededor de la mano\n",
    "        x_min = min(x_min, x)\n",
    "        y_min = min(y_min, y)\n",
    "        x_max = max(x_max, x)\n",
    "        y_max = max(y_max, y)\n",
    "\n",
    "    # Definir conexiones solo para el contorno de la mano y los dedos\n",
    "    connections = [[1, 2], [2, 3], [3, 4],  # Dedo pulgar\n",
    "                   [5, 6], [6, 7], [7, 8],  # Dedo índice\n",
    "                   [9, 10], [10, 11], [11, 12],  # Dedo medio\n",
    "                   [13, 14], [14, 15], [15, 16],  # Dedo anular\n",
    "                   [17, 18], [18, 19], [19, 20],  # Dedo meñique\n",
    "                   [0, 1],[0, 17],[1, 5], [5, 9], [9, 13], [13, 17]]  # Conexiones de la palma de la mano\n",
    "\n",
    "    # Dibujar las conexiones entre los puntos de referencia de la mano\n",
    "    for connection in connections:\n",
    "        cv2.line(frame, (int(landmarks.landmark[connection[0]].x * width), int(landmarks.landmark[connection[0]].y * height)),\n",
    "                         (int(landmarks.landmark[connection[1]].x * width), int(landmarks.landmark[connection[1]].y * height)), (0, 0, 255), 2)\n",
    "\n",
    "    hand_width = x_max - x_min\n",
    "    hand_height = y_max - y_min\n",
    "\n",
    "    # Calculate the side length of the square bounding box\n",
    "    square_side = max(hand_width, hand_height)\n",
    "\n",
    "    # Calculate the coordinates of the square bounding box\n",
    "    x_min_square = x_min + hand_width // 2 - square_side // 2\n",
    "    x_max_square = x_min_square + square_side\n",
    "    y_min_square = y_min + hand_height // 2 - square_side // 2\n",
    "    y_max_square = y_min_square + square_side\n",
    "\n",
    "    # Añadir un margen al cuadrado\n",
    "    x_min_square = max(0, x_min_square)\n",
    "    y_min_square = max(0, y_min_square)\n",
    "    x_max_square = min(width, x_max_square)\n",
    "    y_max_square = min(height, y_max_square)\n",
    "\n",
    "    # Dibujar el cuadrado que rodea la mano\n",
    "    cv2.rectangle(frame, (x_min_square-margin, y_min_square-margin), (x_max_square+margin, y_max_square+margin), (0, 0, 255), 2)\n",
    "\n",
    "    # Return the square bounding box instead of the hand rectangle\n",
    "    return frame, (x_min_square-margin, y_min_square-margin, x_max_square+margin, y_max_square+margin)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def capture_frames(hands, classes, path, num_frames=200):\n",
    "    classes_idx = {c: i for i, c in enumerate(classes)}\n",
    "\n",
    "    cap = cv2.VideoCapture(0)  # Inicializa la cámara\n",
    "\n",
    "    makedir(path)  # Crea la carpeta 'data' si no existe\n",
    "\n",
    "    for c in classes:\n",
    "        makedir(path + c)\n",
    "    letter_idx = 0  # Índice de la letra actual\n",
    "    frames_taken = 0  # Contador para el número de frames tomados por letra\n",
    "\n",
    "    frames_dataframe = []\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()  # Lee un frame de la cámara\n",
    "\n",
    "        # Si no se pudo leer el frame, termina el ciclo\n",
    "        if not ret:\n",
    "            print(\"Error al leer el frame\")\n",
    "            break\n",
    "\n",
    "        img = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)  # Convierte el frame de BGR a RGB\n",
    "\n",
    "        hands_results = hands.process(img)  # Procesa el frame con el modelo de manos\n",
    "\n",
    "        # Dibuja puntos y líneas para las manos en la imagen negra\n",
    "        if hands_results.multi_hand_landmarks:\n",
    "            for landmarks in hands_results.multi_hand_landmarks:\n",
    "                drawn_frame, hand_rect = draw_hand_landmarks(frame, landmarks)  # Dibuja puntos y líneas para las mano\n",
    "                \n",
    "                if frames_taken < num_frames:\n",
    "                    letter = classes[letter_idx]  # Obtiene la letra actual\n",
    "\n",
    "                    # recortar la mano y guardarla \n",
    "                    try:\n",
    "                        reshaped_frame = drawn_frame[hand_rect[1]:hand_rect[3], hand_rect[0]:hand_rect[2]] # Recorta el cuadrado que rodea la mano y lo redimensiona\n",
    "                        reshaped_frame = cv2.cvtColor(reshaped_frame, cv2.COLOR_BGR2GRAY)  # Convierte la imagen a escala de grises\n",
    "                        reshaped_frame = cv2.resize(reshaped_frame, (28, 28), interpolation=cv2.INTER_AREA) # Redimensiona la imagen a 28x28 píxel  es\n",
    "                        \n",
    "                        # guardar el frame en el dataframe\n",
    "                        frames_dataframe.append([classes_idx[letter]] + reshaped_frame.flatten().tolist())\n",
    "\n",
    "                        # reshaped_frame = reshaped_frame.reshape(1, 28, 28,  1)\n",
    "                        frames_taken += 1  # Incrementa el contador de frames tomados\n",
    "\n",
    "                    except Exception as e:\n",
    "                        print(e)\n",
    "                        pass\n",
    "                            \n",
    "                if frames_taken >= num_frames:\n",
    "                    time.sleep(3)\n",
    "                    letter_idx += 1\n",
    "                    frames_taken = 0\n",
    "                if letter_idx >= len(classes):\n",
    "                    pd.DataFrame(frames_dataframe, columns=['label'] + ['pixel'+str(i) for i in range(len(frames_dataframe[0])-1)]).to_csv(f'{path}/frames{time.strftime(\"%Y%m%d%H%M%S\")}.csv', index=False)\n",
    "                    break\n",
    "            \n",
    "            cv2.putText(drawn_frame, letter + ' ' + str(frames_taken), (30, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
    "        cv2.imshow('Pose Detection', frame)  # Muestra el frame con las manos detectadas\n",
    "        \n",
    "        # Si se presiona la tecla 'q', termina el ciclo\n",
    "        if (cv2.waitKey(1) & 0xFF == ord('q')) or letter_idx >= len(classes):\n",
    "            break\n",
    "\n",
    "    cap.release()  # Libera la cámara\n",
    "    cv2.destroyAllWindows() # Cerrar todas las ventanas\n",
    "    hands.close() # Cerrar el modelo de manos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A', 'B', 'C', 'D', 'E', 'F', 'G', 'I', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1717160589.746552  361031 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1717160589.747662  374274 gl_context.cc:357] GL version: 3.2 (OpenGL ES 3.2 Mesa 24.0.6-manjaro1.1), renderer: Mesa Intel(R) Xe Graphics (TGL GT2)\n"
     ]
    }
   ],
   "source": [
    "mp_hands = mp.solutions.hands # Importar el modelo de manos de MediaPipe\n",
    "hands = mp_hands.Hands(max_num_hands=1) # Inicializar el modelo de manos\n",
    "\n",
    "# Ruta de la carpeta donde se guardarán las imágenes en formato csv\n",
    "path_db = f'data/backups/'\n",
    "classes = list(json.load(open(f'{path_db}classes.json')).keys())\n",
    "print(classes)\n",
    "# capture_frames(hands, classes, path_db) # Capturar frames de la cámara y guardarlos en carpetas correspondientes a cada letra\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
