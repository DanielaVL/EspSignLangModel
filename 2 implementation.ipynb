{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definición de los estimadores de pose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# # Función para dibujar puntos de la pose del cuerpo\n",
    "# def draw_pose_landmarks(frame, landmarks, COLOR):\n",
    "#     height, width, _ = frame.shape\n",
    "#     for point in landmarks.landmark:\n",
    "#         x, y = int(point.x * width), int(point.y * height)\n",
    "#         cv2.circle(frame, (x, y), 5, COLOR, -1)\n",
    "\n",
    "# # Función para dibujar cuadro de la cara\n",
    "# def draw_face_detection(frame, detections, COLOR):\n",
    "#     height, width, _ = frame.shape\n",
    "#     for detection in detections:\n",
    "#         bboxC = detection.location_data.relative_bounding_box\n",
    "#         ih, iw, _ = frame.shape\n",
    "#         bbox = int(bboxC.xmin * iw), int(bboxC.ymin * ih), int(bboxC.width * iw), int(bboxC.height * ih)\n",
    "#         cv2.rectangle(frame, bbox, COLOR, 2)\n",
    "        \n",
    "# Función para dibujar puntos y líneas de las manos\n",
    "def draw_hand_landmarks(frame, landmarks, COLOR):\n",
    "    height, width, _ = frame.shape\n",
    "    x_min, y_min, x_max, y_max = width, height, 0, 0\n",
    "    \n",
    "    # Dibujar puntos y líneas de las manos\n",
    "    for i, point in enumerate(landmarks.landmark):\n",
    "        x, y = int(point.x * width), int(point.y * height)\n",
    "        color = (0, 255, 0) if i % 4 == 0 else (0, 0, 255)\n",
    "        cv2.circle(frame, (x, y), int(height * 0.01), color, -1)\n",
    "        # Actualizar los límites del cuadrado\n",
    "        x_min = min(x_min, x)\n",
    "        y_min = min(y_min, y)\n",
    "        x_max = max(x_max, x)\n",
    "        y_max = max(y_max, y)\n",
    "    \n",
    "    connections = [[0, 1], [1, 2], [2, 3], [3, 4], [0, 5], [5, 6], [6, 7], [7, 8], [0, 9], [9, 10], [10, 11], [11, 12], [0, 13], [13, 14], [14, 15], [15, 16], [0, 17], [17, 18], [18, 19], [19, 20]]\n",
    "    for connection in connections:\n",
    "        cv2.line(frame, (int(landmarks.landmark[connection[0]].x * width), int(landmarks.landmark[connection[0]].y * height)),\n",
    "                 (int(landmarks.landmark[connection[1]].x * width), int(landmarks.landmark[connection[1]].y * height)), COLOR, 2)\n",
    "    cv2.rectangle(frame, (x_min, y_min), (x_max, y_max), (255, 0, 255), 2)\n",
    "\n",
    "# Inicializar los modelos de MediaPipe\n",
    "# mp_pose = mp.solutions.pose\n",
    "# mp_face = mp.solutions.face_detection\n",
    "mp_hands = mp.solutions.hands\n",
    "\n",
    "# pose = mp_pose.Pose()\n",
    "# face_detection = mp_face.FaceDetection()\n",
    "hands = mp_hands.Hands()\n",
    "\n",
    "# Constantes para colores\n",
    "# RED = (0, 0, 255)\n",
    "# GREEN = (0, 255, 0)\n",
    "BLUE = (255, 0, 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Captura en tiempo real de la pose de una seña"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"Error al abrir la cámara\")\n",
    "else:\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Error al leer el frame\")\n",
    "            break\n",
    "\n",
    "        # height, width, _ = frame.shape\n",
    "\n",
    "        img = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Detección de la pose del cuerpo\n",
    "        # pose_results = pose.process(img)\n",
    "\n",
    "        # Detección de las manos\n",
    "        hands_results = hands.process(img)\n",
    "\n",
    "        # Detección de la cara\n",
    "        # face_results = face_detection.process(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "        # Crear una imagen negra del mismo tamaño que el frame\n",
    "        black_frame = np.zeros_like(frame)\n",
    "\n",
    "        # Dibujar puntos y líneas para la pose del cuerpo en la imagen negra\n",
    "        # if pose_results.pose_landmarks:\n",
    "        #     draw_pose_landmarks(black_frame, pose_results.pose_landmarks)\n",
    "\n",
    "        # Dibujar círculos y líneas para las manos en la imagen negra\n",
    "        if hands_results.multi_hand_landmarks:\n",
    "            for landmarks in hands_results.multi_hand_landmarks:\n",
    "                draw_hand_landmarks(black_frame, landmarks, BLUE)\n",
    "\n",
    "        # Dibujar puntos y cuadro de la cara en la imagen original\n",
    "        # if face_results.detections:\n",
    "        #     draw_face_detection(frame, face_results.detections)\n",
    "\n",
    "        cv2.imshow('Pose Detection', black_frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Refactorización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "\n",
    "def draw_hand_landmarks(frame, landmarks, COLOR):\n",
    "    height, width, _ = frame.shape\n",
    "    x_min, y_min, x_max, y_max = width, height, 0, 0\n",
    "    \n",
    "    for i, point in enumerate(landmarks.landmark):\n",
    "        x, y = int(point.x * width), int(point.y * height)\n",
    "        color = (0, 255, 0) if i % 4 == 0 else (0, 0, 255)\n",
    "        cv2.circle(frame, (x, y), int(height * 0.01), color, -1)\n",
    "        \n",
    "        # Actualizar las coordenadas mínimas y máximas para dibujar un rectángulo alrededor de la mano\n",
    "        x_min = min(x_min, x)\n",
    "        y_min = min(y_min, y)\n",
    "        x_max = max(x_max, x)\n",
    "        y_max = max(y_max, y)\n",
    "\n",
    "    connections = [[0, 1], [1, 2], [2, 3], [3, 4], [0, 5], [5, 6], [6, 7], [7, 8], [0, 9], [9, 10], [10, 11], [11, 12], [0, 13], [13, 14], [14, 15], [15, 16], [0, 17], [17, 18], [18, 19], [19, 20]]\n",
    "    \n",
    "    for connection in connections:\n",
    "        cv2.line(frame, (int(landmarks.landmark[connection[0]].x * width), int(landmarks.landmark[connection[0]].y * height)),\n",
    "                 (int(landmarks.landmark[connection[1]].x * width), int(landmarks.landmark[connection[1]].y * height)), COLOR, 2)\n",
    "    \n",
    "    # Dibujar un rectángulo alrededor de la mano\n",
    "    cv2.rectangle(frame, (x_min, y_min), (x_max, y_max), (255, 0, 255), 2)\n",
    "\n",
    "mp_hands = mp.solutions.hands\n",
    "hands = mp_hands.Hands()\n",
    "BLUE = (255, 0, 0)\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"Error al abrir la cámara\")\n",
    "else:\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Error al leer el frame\")\n",
    "            break\n",
    "        img = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        hands_results = hands.process(img)\n",
    "        black_frame = np.zeros_like(frame)\n",
    "        \n",
    "        if hands_results.multi_hand_landmarks:\n",
    "            for landmarks in hands_results.multi_hand_landmarks:\n",
    "                draw_hand_landmarks(black_frame, landmarks, BLUE)\n",
    "        \n",
    "        cv2.imshow('Pose Detection', black_frame)\n",
    "        \n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "\n",
    "def draw_hand_landmarks(frame, landmarks, COLOR):\n",
    "    height, width, _ = frame.shape\n",
    "    x_min, y_min, x_max, y_max = width, height, 0, 0\n",
    "    \n",
    "    for i, point in enumerate(landmarks.landmark):\n",
    "        x, y = int(point.x * width), int(point.y * height)\n",
    "        color = (0, 255, 0) if i % 4 == 0 else (0, 0, 255)\n",
    "        cv2.circle(frame, (x, y), int(height * 0.01), color, -1)\n",
    "        \n",
    "        # Actualizar las coordenadas mínimas y máximas para dibujar un rectángulo alrededor de la mano\n",
    "        x_min = min(x_min, x)\n",
    "        y_min = min(y_min, y)\n",
    "        x_max = max(x_max, x)\n",
    "        y_max = max(y_max, y)\n",
    "\n",
    "    connections = [[0, 1], [1, 2], [2, 3], [3, 4], [0, 5], [5, 6], [6, 7], [7, 8], [0, 9], [9, 10], [10, 11], [11, 12], [0, 13], [13, 14], [14, 15], [15, 16], [0, 17], [17, 18], [18, 19], [19, 20]]\n",
    "    \n",
    "    for connection in connections:\n",
    "        cv2.line(frame, (int(landmarks.landmark[connection[0]].x * width), int(landmarks.landmark[connection[0]].y * height)),\n",
    "                 (int(landmarks.landmark[connection[1]].x * width), int(landmarks.landmark[connection[1]].y * height)), COLOR, 2)\n",
    "    \n",
    "    # Dibujar un rectángulo alrededor de la mano\n",
    "    cv2.rectangle(frame, (x_min, y_min), (x_max, y_max), (255, 0, 255), 2)\n",
    "    return frame, (x_min, y_min, x_max, y_max)\n",
    "\n",
    "def capture_frames(period, folder, num_frames):\n",
    "    # crear carpeta de clases\n",
    "    if not os.path.exists(folder):\n",
    "        os.makedirs(folder)\n",
    "\n",
    "    letters = [chr(i) for i in range(65, 91)]  # Letras del alfabeto A-Z\n",
    "\n",
    "    # crear subcarpetas para cada letra del alfabeto\n",
    "    for letter in letters:\n",
    "        letter_folder = os.path.join(folder, letter)\n",
    "        if not os.path.exists(letter_folder):\n",
    "            os.makedirs(letter_folder)\n",
    "\n",
    "    cap = cv2.VideoCapture(0) # Inicializar la cámara\n",
    "    count = 0 # Contador para capturar frames\n",
    "    letter_idx = 0 # Índice de la letra actual\n",
    "    frames_taken = 0 # Contador para el número de frames tomados por letra\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read() # Leer un frame de la cámara\n",
    "\n",
    "        # Si no se pudo leer el frame, terminar el ciclo\n",
    "        if not ret:\n",
    "            print(\"Error al leer el frame\")\n",
    "            break\n",
    "\n",
    "        img = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB) # Convertir el frame a RGB\n",
    "        hands_results = hands.process(img) # Procesar el frame con el modelo de manos\n",
    "        black_frame = np.zeros_like(frame) # Crear una imagen negra del mismo tamaño que el frame\n",
    "\n",
    "        # Dibujar puntos y líneas para las manos en la imagen negra\n",
    "        if hands_results.multi_hand_landmarks:\n",
    "            for landmarks in hands_results.multi_hand_landmarks:\n",
    "                drawn_frame, hand_rect = draw_hand_landmarks(black_frame, landmarks, BLUE) # Dibujar puntos y líneas para las manos\n",
    "                # Guardar el frame en la carpeta correspondiente\n",
    "                if count % period == 0 and frames_taken < num_frames:\n",
    "                    letter = letters[letter_idx] # Obtener la letra actual\n",
    "                    letter_folder = os.path.join(folder, letter) # Obtener la carpeta correspondiente a la letra\n",
    "                    try: \n",
    "                        frame_resized = cv2.resize(drawn_frame[hand_rect[1]:hand_rect[3], hand_rect[0]:hand_rect[2]], (512, 512)) # Redimensionar el frame\n",
    "                        cv2.imwrite(os.path.join(letter_folder, f\"{time.time()}.jpg\"), frame_resized) # Guardar el frame en la carpeta\n",
    "                        frames_taken += 1 # Incrementar el contador de frames tomados por letra\n",
    "                        count = 0 # Reiniciar el contador\n",
    "                    except: \n",
    "                        pass\n",
    "                if frames_taken >= num_frames:\n",
    "                    frames_taken = 0 # Reiniciar el contador de frames tomados por letra\n",
    "                    letter_idx = (letter_idx + 1) % len(letters) # Cambiar a la siguiente letra\n",
    "                count += 1\n",
    "\n",
    "       \n",
    "        cv2.putText(black_frame, f'Letra: {letters[letter_idx]}', (10, 40), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
    "        cv2.putText(black_frame, f'Capturas: {frames_taken}', (10, 70), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2) \n",
    "        cv2.imshow('Pose Detection', black_frame) # Mostrar el frame con las manos detectadas\n",
    "        \n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break # Si se presiona la tecla 'q', terminar el ciclo\n",
    "\n",
    "    cap.release() # Liberar la cámara\n",
    "    cv2.destroyAllWindows() # Cerrar todas las ventanas\n",
    "    hands.close() # Cerrar el modelo de manos\n",
    "\n",
    "mp_hands = mp.solutions.hands # Importar el modelo de manos de MediaPipe\n",
    "hands = mp_hands.Hands() # Inicializar el modelo de manos\n",
    "BLUE = (255, 0, 0) # Color azul\n",
    "\n",
    "capture_frames(50, \"classes_poses_cut\", 20) # Capturar frames cada 5 frames y guardar 20 frames por letra\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uso del modelo en tiempo real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "import cv2\n",
    "\n",
    "\n",
    "model = load_model('model.h5')\n",
    "\n",
    "class_indices = json.load(open('class_indices.json'))\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    img = cv2.resize(frame, (224, 224))\n",
    "    # img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    img = tf.keras.applications.mobilenet_v2.preprocess_input(img)\n",
    "    prediction = model.predict(img)\n",
    "    predicted_class = list(class_indices.keys())[np.argmax(prediction)]\n",
    "    cv2.putText(frame, predicted_class, (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "    cv2.imshow('frame', frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "model = load_model('model.h5')\n",
    "\n",
    "class_indices = json.load(open('class_indices.json'))\n",
    "\n",
    "def predict_image(model, img_path, class_indices):\n",
    "    img = image.load_img(img_path, target_size=(224, 224))\n",
    "    img = image.img_to_array(img)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    img = tf.keras.applications.mobilenet_v2.preprocess_input(img)\n",
    "    prediction = model.predict(img)\n",
    "    predicted_class = list(class_indices.keys())[np.argmax(prediction)]\n",
    "    return predicted_class\n",
    "\n",
    "img_path = \"./classes_original/M/DSC01254.JPG\"\n",
    "predicted_class = predict_image(model, img_path, class_indices)\n",
    "print(predicted_class)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
